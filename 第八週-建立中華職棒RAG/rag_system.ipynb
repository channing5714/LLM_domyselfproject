{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53700dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: ç”¨Linux æŒ‡ä»¤ï¼Œè®€å…¥ä¸€å€‹åœ¨ç¶²è·¯ä¸Šçš„ï¼Œç¶²å€æ˜¯URLçš„æª”æ¡ˆ\n",
    "\n",
    "# å°‡URLæ›¿æ›ç‚ºæ‚¨è¦ä¸‹è¼‰çš„æª”æ¡ˆçš„å¯¦éš›ç¶²å€\n",
    "URL = \"https://drive.google.com/uc?export=download&id=1wJUq74hxSE0u6GS11yUFCjAs4jpqSnwa\"  \n",
    "\n",
    "# ä½¿ç”¨ wget ä¸‹è¼‰æª”æ¡ˆï¼Œä¸¦å°‡å…¶å‘½åç‚º downloaded_file.txt\n",
    "!wget -O faiss_db.zip \"$URL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00a89b",
   "metadata": {},
   "source": [
    "!unzip faiss_db.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7842aa6",
   "metadata": {},
   "source": [
    "å®‰è£ä¸¦å¼•å…¥å¿…è¦å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community sentence-transformers faiss-cpu gradio openai # å®‰è£å¿…è¦å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d456715",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704bace",
   "metadata": {},
   "source": [
    "### 2. è‡ªè¨‚ E5 embedding é¡åˆ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomE5Embedding(HuggingFaceEmbeddings):\n",
    "    def embed_documents(self, texts):\n",
    "        texts = [f\"passage: {t}\" for t in texts]\n",
    "        return super().embed_documents(texts)\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return super().embed_query(f\"query: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dc9e8",
   "metadata": {},
   "source": [
    "### 3. è¼‰å…¥ faiss_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = CustomE5Embedding(model_name=\"intfloat/multilingual-e5-small\")\n",
    "db = FAISS.load_local(\"faiss_db\", embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f692d",
   "metadata": {},
   "source": [
    "### 4. è¨­å®šå¥½æˆ‘å€‘è¦çš„ LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4670c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = userdata.get('Groq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3-70b-8192\"\n",
    "base_url=\"https://api.groq.com/openai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=base_url # ä½¿ç”¨ OpenAI æœ¬èº«ä¸éœ€è¦é€™æ®µ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50067db",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"ä½ æ˜¯æ”¿å¤§çš„ AI è‡ªä¸»å­¸ç¿’è¼”å°å“¡ï¼Œè«‹æ ¹æ“šè³‡æ–™ä¾†å›æ‡‰å­¸ç”Ÿçš„å•é¡Œã€‚è«‹è¦ªåˆ‡ã€ç°¡æ½”ä¸¦é™„å¸¶å…·é«”å»ºè­°ã€‚è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›æ‡‰ã€‚\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "æ ¹æ“šä¸‹åˆ—è³‡æ–™å›ç­”å•é¡Œï¼š\n",
    "{retrieved_chunks}\n",
    "\n",
    "ä½¿ç”¨è€…çš„å•é¡Œæ˜¯ï¼š{question}\n",
    "\n",
    "è«‹æ ¹æ“šè³‡æ–™å…§å®¹å›è¦†ï¼Œè‹¥è³‡æ–™ä¸è¶³è«‹å‘Šè¨´åŒå­¸å¯ä»¥è«‹æ•™å­¸å‹™è™•èª²å¤–æ´»å‹•çµ„çš„è€å¸«ã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25810485",
   "metadata": {},
   "source": [
    "### 6. ä½¿ç”¨ RAG ä¾†å›æ‡‰\n",
    "\n",
    "æœå°‹èˆ‡ä½¿ç”¨è€…å•é¡Œç›¸é—œçš„è³‡è¨Šï¼Œæ ¹æ“šæˆ‘å€‘çš„ prompt æ¨£ç‰ˆå»è®“ LLM å›æ‡‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "def chat_with_rag(user_input):\n",
    "    global chat_history\n",
    "    # å–å›ç›¸é—œè³‡æ–™\n",
    "    docs = retriever.get_relevant_documents(user_input)\n",
    "    retrieved_chunks = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # å°‡è‡ªå®š prompt å¥—å…¥æ ¼å¼\n",
    "    final_prompt = prompt_template.format(retrieved_chunks=retrieved_chunks, question=user_input)\n",
    "\n",
    "    # å‘¼å« OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": final_prompt},\n",
    "    ]\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append((user_input, answer))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff27a92",
   "metadata": {},
   "source": [
    "### 7. ç”¨ Gradio æ‰“é€  Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ğŸ“ AI è‡ªä¸»å­¸ç¿’è«®è©¢å¸«\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"è«‹è¼¸å…¥ä½ çš„å•é¡Œ...\")\n",
    "\n",
    "    def respond(message, chat_history_local):\n",
    "        response = chat_with_rag(message)\n",
    "        chat_history_local.append((message, response))\n",
    "        return \"\", chat_history_local\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
